{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 20:27:12.336071: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-05 20:27:12.336203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-05 20:27:12.336248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-05 20:27:12.336325: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-05 20:27:12.336373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-05 20:27:12.336418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10226 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset hyperparameters\n",
    "unlabeled_dataset_size = 7294\n",
    "labeled_dataset_size = 400\n",
    "image_size = 96\n",
    "image_channels = 3\n",
    "\n",
    "# Algorithm hyperparameters\n",
    "num_epochs = 10\n",
    "batch_size = 256  # Corresponds to 200 steps per epoch\n",
    "width = 128\n",
    "temperature = 0.1\n",
    "# Stronger augmentations for contrastive, weaker ones for supervised training\n",
    "contrastive_augmentation = {\"min_area\": 0.25, \"brightness\": 0.6, \"jitter\": 0.2}\n",
    "classification_augmentation = {\"min_area\": 0.75, \"brightness\": 0.3, \"jitter\": 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7294\n",
      "400\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "unlabel_path = \"./unlabeled\"\n",
    "unlabel_files = os.listdir(unlabel_path)\n",
    "unlabel_files = [os.path.join(unlabel_path, i) for i in unlabel_files]\n",
    "\n",
    "label_path = \"./test\"\n",
    "label_fold_files = os.listdir(label_path)\n",
    "label_fold_files = [os.path.join(label_path, i) for i in label_fold_files]\n",
    "label_train_files = list()\n",
    "label_test_files = list()\n",
    "for fold in label_fold_files:\n",
    "    fold_files = os.listdir(fold)\n",
    "    train, test = train_test_split(fold_files, shuffle=True, test_size=0.2)\n",
    "    label_train_files.extend([(os.path.join(fold, i), fold.split('/')[-1]) for i in train])\n",
    "    label_test_files.extend([(os.path.join(fold, i), fold.split('/')[-1]) for i in test])\n",
    "\n",
    "print(len(unlabel_files))\n",
    "print(len(label_train_files))\n",
    "print(len(label_test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('./test/3/0261.jpg', '3')\n",
      "('./test/3/0317.jpg', '3')\n"
     ]
    }
   ],
   "source": [
    "print(label_train_files[0])\n",
    "print(label_test_files[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def read_mri(mri_path):\n",
    "    mri_data = cv2.imread(mri_path)\n",
    "    return mri_data\n",
    "\n",
    "def unlabel_data_generator(filename_list, batch_size=1):\n",
    "    idx = 0\n",
    "    while idx<len(filename_list):\n",
    "        pixel_data_list = list()\n",
    "        ground_true_list = list()\n",
    "        for j in range(batch_size):\n",
    "            if idx>=len(filename_list):\n",
    "                break\n",
    "            mri_filename = filename_list[idx]\n",
    "            mri_filename = mri_filename.decode('ascii')\n",
    "            pixel_data = read_mri(mri_filename)\n",
    "            pixel_data_list.append(pixel_data)\n",
    "            idx += 1\n",
    "        yield (np.array(pixel_data_list), np.array([None]*len(pixel_data_list)))\n",
    "\n",
    "\n",
    "def label_data_generator(filename_list, batch_size=1):\n",
    "    idx = 0\n",
    "    while idx<len(filename_list):\n",
    "        mri_data_list = list()\n",
    "        ground_true_list = list()\n",
    "        for j in range(batch_size):\n",
    "            if idx>=len(filename_list):\n",
    "                break\n",
    "            mri_filename, y_true = filename_list[idx]\n",
    "            mri_filename = mri_filename.decode('ascii')\n",
    "            pixel_data = read_mri(mri_filename)\n",
    "            mri_data_list.append(pixel_data)\n",
    "            ground_true_list.append(y_true)\n",
    "            idx += 1\n",
    "        yield (np.array(mri_data_list), np.array(ground_true_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate Dataset\n",
    "unlabel_dataset = tf.data.Dataset.from_generator(\n",
    "    unlabel_data_generator,\n",
    "    args=(unlabel_files, batch_size),\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, 96, 96, 3], [None])\n",
    ")\n",
    "\n",
    "label_train_dataset = tf.data.Dataset.from_generator(\n",
    "    label_data_generator,\n",
    "    args=(label_train_files, batch_size),\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, 96, 96, 3], [None])\n",
    ")\n",
    "\n",
    "label_test_dataset = tf.data.Dataset.from_generator(\n",
    "    label_data_generator,\n",
    "    args=(label_test_files, batch_size),\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, 96, 96, 3], [None])\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distorts the color distibutions of images\n",
    "class RandomColorAffine(layers.Layer):\n",
    "    def __init__(self, brightness=0, jitter=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.brightness = brightness\n",
    "        self.jitter = jitter\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"brightness\": self.brightness, \"jitter\": self.jitter})\n",
    "        return config\n",
    "\n",
    "    def call(self, images, training=True):\n",
    "        if training:\n",
    "            batch_size = tf.shape(images)[0]\n",
    "\n",
    "            # Same for all colors\n",
    "            brightness_scales = 1 + tf.random.uniform(\n",
    "                (batch_size, 1, 1, 1), minval=-self.brightness, maxval=self.brightness\n",
    "            )\n",
    "            # Different for all colors\n",
    "            jitter_matrices = tf.random.uniform(\n",
    "                (batch_size, 1, 3, 3), minval=-self.jitter, maxval=self.jitter\n",
    "            )\n",
    "\n",
    "            color_transforms = (\n",
    "                tf.eye(3, batch_shape=[batch_size, 1]) * brightness_scales\n",
    "                + jitter_matrices\n",
    "            )\n",
    "            images = tf.clip_by_value(tf.matmul(images, color_transforms), 0, 1)\n",
    "        return images\n",
    "\n",
    "# Image augmentation module\n",
    "def get_augmenter(min_area, brightness, jitter):\n",
    "    zoom_factor = 1.0 - math.sqrt(min_area)\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(image_size, image_size, image_channels)),\n",
    "            layers.Rescaling(1 / 255),\n",
    "            layers.RandomFlip(\"horizontal\"),\n",
    "            layers.RandomTranslation(zoom_factor / 2, zoom_factor / 2),\n",
    "            layers.RandomZoom((-zoom_factor, 0.0), (-zoom_factor, 0.0)),\n",
    "            RandomColorAffine(brightness, jitter),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "def get_encoder():\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(image_size, image_size, image_channels)),\n",
    "            layers.Conv2D(width, kernel_size=3, strides=2, activation=\"relu\"),\n",
    "            layers.Conv2D(width, kernel_size=3, strides=2, activation=\"relu\"),\n",
    "            layers.Conv2D(width, kernel_size=3, strides=2, activation=\"relu\"),\n",
    "            layers.Conv2D(width, kernel_size=3, strides=2, activation=\"relu\"),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(width, activation=\"relu\"),\n",
    "        ],\n",
    "        name=\"encoder\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 47, 47, 128)       3584      \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 23, 23, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 11, 11, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 5, 5, 128)         147584    \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 3200)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               409728    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 856,064\n",
      "Trainable params: 856,064\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"projection_head\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,024\n",
      "Trainable params: 33,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"linear_probe\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_17 (Dense)            (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 516\n",
      "Trainable params: 516\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "(<tf.Tensor 'IteratorGetNext:0' shape=(None, 96, 96, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>)\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "(<tf.Tensor 'IteratorGetNext:0' shape=(None, 96, 96, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>)\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "     29/Unknown - 122s 4s/step - c_loss: 5.4320 - c_acc: 0.0161 - p_loss: 0.0000e+00 - p_acc: 0.0000e+00WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa09c89e3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "29/29 [==============================] - 122s 4s/step - c_loss: 5.4320 - c_acc: 0.0161 - p_loss: 0.0000e+00 - p_acc: 0.0000e+00 - val_p_loss: 1.8903 - val_p_acc: 0.2500\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 118s 4s/step - c_loss: 5.2331 - c_acc: 0.0179 - p_loss: 0.0000e+00 - p_acc: 0.0000e+00 - val_p_loss: 1.3934 - val_p_acc: 0.2500\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 119s 4s/step - c_loss: 5.0514 - c_acc: 0.0284 - p_loss: 0.0000e+00 - p_acc: 0.0000e+00 - val_p_loss: 1.3756 - val_p_acc: 0.2500\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 118s 4s/step - c_loss: 4.8789 - c_acc: 0.0349 - p_loss: 0.0000e+00 - p_acc: 0.0000e+00 - val_p_loss: 1.3814 - val_p_acc: 0.2500\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 118s 4s/step - c_loss: 4.6866 - c_acc: 0.0489 - p_loss: 0.0000e+00 - p_acc: 0.0000e+00 - val_p_loss: 1.3655 - val_p_acc: 0.2675\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 119s 4s/step - c_loss: 4.5324 - c_acc: 0.0587 - p_loss: 0.0000e+00 - p_acc: 0.0000e+00 - val_p_loss: 1.3973 - val_p_acc: 0.2500\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 119s 4s/step - c_loss: 4.3688 - c_acc: 0.0687 - p_loss: 0.0000e+00 - p_acc: 0.0000e+00 - val_p_loss: 1.3910 - val_p_acc: 0.2500\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 118s 4s/step - c_loss: 4.1691 - c_acc: 0.0875 - p_loss: 0.0000e+00 - p_acc: 0.0000e+00 - val_p_loss: 1.4028 - val_p_acc: 0.2250\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 119s 4s/step - c_loss: 3.9643 - c_acc: 0.1096 - p_loss: 0.0000e+00 - p_acc: 0.0000e+00 - val_p_loss: 1.3963 - val_p_acc: 0.2350\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 118s 4s/step - c_loss: 3.7305 - c_acc: 0.1389 - p_loss: 0.0000e+00 - p_acc: 0.0000e+00 - val_p_loss: 1.3960 - val_p_acc: 0.2125\n",
      "Maximal validation accuracy: 26.75%\n"
     ]
    }
   ],
   "source": [
    "# Define the contrastive model with model-subclassing\n",
    "class ContrastiveModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.temperature = temperature\n",
    "        self.contrastive_augmenter = get_augmenter(**contrastive_augmentation)\n",
    "        self.classification_augmenter = get_augmenter(**classification_augmentation)\n",
    "        self.encoder = get_encoder()\n",
    "        # Non-linear MLP as projection head\n",
    "        self.projection_head = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=(width,)),\n",
    "                layers.Dense(width, activation=\"relu\"),\n",
    "                layers.Dense(width),\n",
    "            ],\n",
    "            name=\"projection_head\",\n",
    "        )\n",
    "        # Single dense layer for linear probing\n",
    "        self.linear_probe = keras.Sequential(\n",
    "            [layers.Input(shape=(width,)), layers.Dense(4)], name=\"linear_probe\"\n",
    "        )\n",
    "\n",
    "        self.encoder.summary()\n",
    "        self.projection_head.summary()\n",
    "        self.linear_probe.summary()\n",
    "\n",
    "    def compile(self, contrastive_optimizer, probe_optimizer, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "\n",
    "        self.contrastive_optimizer = contrastive_optimizer\n",
    "        self.probe_optimizer = probe_optimizer\n",
    "\n",
    "        # self.contrastive_loss will be defined as a method\n",
    "        self.probe_loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "        self.contrastive_loss_tracker = keras.metrics.Mean(name=\"c_loss\")\n",
    "        self.contrastive_accuracy = keras.metrics.SparseCategoricalAccuracy(\n",
    "            name=\"c_acc\"\n",
    "        )\n",
    "        self.probe_loss_tracker = keras.metrics.Mean(name=\"p_loss\")\n",
    "        self.probe_accuracy = keras.metrics.SparseCategoricalAccuracy(name=\"p_acc\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.contrastive_loss_tracker,\n",
    "            self.contrastive_accuracy,\n",
    "            self.probe_loss_tracker,\n",
    "            self.probe_accuracy,\n",
    "        ]\n",
    "\n",
    "    def contrastive_loss(self, projections_1, projections_2):\n",
    "        # InfoNCE loss (information noise-contrastive estimation)\n",
    "        # NT-Xent loss (normalized temperature-scaled cross entropy)\n",
    "\n",
    "        # Cosine similarity: the dot product of the l2-normalized feature vectors\n",
    "        projections_1 = tf.math.l2_normalize(projections_1, axis=1)\n",
    "        projections_2 = tf.math.l2_normalize(projections_2, axis=1)\n",
    "        similarities = (\n",
    "            tf.matmul(projections_1, projections_2, transpose_b=True) / self.temperature\n",
    "        )\n",
    "\n",
    "        # The similarity between the representations of two augmented views of the\n",
    "        # same image should be higher than their similarity with other views\n",
    "        batch_size = tf.shape(projections_1)[0]\n",
    "        contrastive_labels = tf.range(batch_size)\n",
    "        self.contrastive_accuracy.update_state(contrastive_labels, similarities)\n",
    "        self.contrastive_accuracy.update_state(\n",
    "            contrastive_labels, tf.transpose(similarities)\n",
    "        )\n",
    "\n",
    "        # The temperature-scaled similarities are used as logits for cross-entropy\n",
    "        # a symmetrized version of the loss is used here\n",
    "        loss_1_2 = keras.losses.sparse_categorical_crossentropy(\n",
    "            contrastive_labels, similarities, from_logits=True\n",
    "        )\n",
    "        loss_2_1 = keras.losses.sparse_categorical_crossentropy(\n",
    "            contrastive_labels, tf.transpose(similarities), from_logits=True\n",
    "        )\n",
    "        return (loss_1_2 + loss_2_1) / 2\n",
    "\n",
    "    def train_step(self, data):\n",
    "        print(data)\n",
    "        (unlabeled_images, _) = data\n",
    "\n",
    "        # Both labeled and unlabeled images are used, without labels\n",
    "        images = tf.concat((unlabeled_images), axis=0)\n",
    "        # Each image is augmented twice, differently\n",
    "        augmented_images_1 = self.contrastive_augmenter(images, training=True)\n",
    "        augmented_images_2 = self.contrastive_augmenter(images, training=True)\n",
    "        with tf.GradientTape() as tape:\n",
    "            features_1 = self.encoder(augmented_images_1, training=True)\n",
    "            features_2 = self.encoder(augmented_images_2, training=True)\n",
    "            # The representations are passed through a projection mlp\n",
    "            projections_1 = self.projection_head(features_1, training=True)\n",
    "            projections_2 = self.projection_head(features_2, training=True)\n",
    "            contrastive_loss = self.contrastive_loss(projections_1, projections_2)\n",
    "        gradients = tape.gradient(\n",
    "            contrastive_loss,\n",
    "            self.encoder.trainable_weights + self.projection_head.trainable_weights,\n",
    "        )\n",
    "        self.contrastive_optimizer.apply_gradients(\n",
    "            zip(\n",
    "                gradients,\n",
    "                self.encoder.trainable_weights + self.projection_head.trainable_weights,\n",
    "            )\n",
    "        )\n",
    "        self.contrastive_loss_tracker.update_state(contrastive_loss)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        labeled_images, labels = data\n",
    "\n",
    "        # For testing the components are used with a training=False flag\n",
    "        preprocessed_images = self.classification_augmenter(\n",
    "            labeled_images, training=False\n",
    "        )\n",
    "        features = self.encoder(preprocessed_images, training=False)\n",
    "        class_logits = self.linear_probe(features, training=False)\n",
    "        probe_loss = self.probe_loss(labels, class_logits)\n",
    "        self.probe_loss_tracker.update_state(probe_loss)\n",
    "        self.probe_accuracy.update_state(labels, class_logits)\n",
    "\n",
    "        # Only the probe metrics are logged at test time\n",
    "        return {m.name: m.result() for m in self.metrics[2:]}\n",
    "\n",
    "\n",
    "# Contrastive pretraining\n",
    "pretraining_model = ContrastiveModel()\n",
    "pretraining_model.compile(\n",
    "    contrastive_optimizer=keras.optimizers.Adam(),\n",
    "    probe_optimizer=keras.optimizers.Adam(),\n",
    ")\n",
    "\n",
    "pretraining_history = pretraining_model.fit(\n",
    "    unlabel_dataset, epochs=num_epochs, validation_data=label_train_dataset\n",
    ")\n",
    "print(\n",
    "    \"Maximal validation accuracy: {:.2f}%\".format(\n",
    "        max(pretraining_history.history[\"val_p_acc\"]) * 100\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "2/2 [==============================] - 4s 817ms/step - loss: 1.5269 - acc: 0.2800 - val_loss: 1.3047 - val_acc: 0.3600\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 3s 742ms/step - loss: 1.2985 - acc: 0.4700 - val_loss: 1.2635 - val_acc: 0.5000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 3s 760ms/step - loss: 1.2683 - acc: 0.5700 - val_loss: 1.2239 - val_acc: 0.3700\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 3s 719ms/step - loss: 1.2258 - acc: 0.4200 - val_loss: 1.1836 - val_acc: 0.3500\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 3s 773ms/step - loss: 1.1781 - acc: 0.3850 - val_loss: 1.1259 - val_acc: 0.3700\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 3s 748ms/step - loss: 1.1026 - acc: 0.4625 - val_loss: 1.0345 - val_acc: 0.4100\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 3s 721ms/step - loss: 1.0163 - acc: 0.5625 - val_loss: 0.9187 - val_acc: 0.5800\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 3s 738ms/step - loss: 0.9075 - acc: 0.6725 - val_loss: 0.8198 - val_acc: 0.6400\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 3s 728ms/step - loss: 0.7886 - acc: 0.7350 - val_loss: 0.7490 - val_acc: 0.7200\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 3s 717ms/step - loss: 0.7158 - acc: 0.7525 - val_loss: 0.7849 - val_acc: 0.7600\n",
      "Maximal validation accuracy: 76.00%\n"
     ]
    }
   ],
   "source": [
    "# Supervised finetuning of the pretrained encoder\n",
    "finetuning_model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(image_size, image_size, image_channels)),\n",
    "        get_augmenter(**classification_augmentation),\n",
    "        pretraining_model.encoder,\n",
    "        layers.Dense(4),\n",
    "    ],\n",
    "    name=\"finetuning_model\",\n",
    ")\n",
    "finetuning_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
    ")\n",
    "\n",
    "finetuning_history = finetuning_model.fit(\n",
    "    label_train_dataset, epochs=num_epochs, validation_data=label_test_dataset\n",
    ")\n",
    "print(\n",
    "    \"Maximal validation accuracy: {:.2f}%\".format(\n",
    "        max(finetuning_history.history[\"val_acc\"]) * 100\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "label_files = label_test_files.copy()\n",
    "label_files.extend(label_train_files)\n",
    "y_true_list = [int(y_true) for (data, y_true) in label_files]\n",
    "print(y_true_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 37ms/step\n",
      "(500, 128)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_dataset = tf.data.Dataset.from_generator(\n",
    "    label_data_generator,\n",
    "    args=(label_files, batch_size),\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, 96, 96, 3], [None])\n",
    ")\n",
    "emb = pretraining_model.encoder.predict(total_dataset)\n",
    "print(emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 128)\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9539999961853027"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def KNN(emb, cls, batch_size, Ks=[1, 10, 50, 100]):\n",
    "    \"\"\"Apply KNN for different K and return the maximum acc\"\"\"\n",
    "    preds = []\n",
    "    mask = torch.eye(batch_size).bool().to(emb.device)\n",
    "    mask = F.pad(mask, (0, len(emb) - batch_size))\n",
    "    for batch_x in torch.split(emb, batch_size):\n",
    "        dist = torch.norm(\n",
    "            batch_x.unsqueeze(1) - emb.unsqueeze(0), dim=2, p=\"fro\")\n",
    "        now_batch_size = len(batch_x)\n",
    "        mask = mask[:now_batch_size]\n",
    "        dist = torch.masked_fill(dist, mask, float('inf'))\n",
    "        # update mask\n",
    "        mask = F.pad(mask[:, :-now_batch_size], (now_batch_size, 0))\n",
    "        pred = []\n",
    "        for K in Ks:\n",
    "            knn = dist.topk(K, dim=1, largest=False).indices\n",
    "            knn = cls[knn].cpu()\n",
    "            pred.append(torch.mode(knn).values)\n",
    "        pred = torch.stack(pred, dim=0)\n",
    "        preds.append(pred)\n",
    "    preds = torch.cat(preds, dim=1)\n",
    "    accs = [(pred == cls.cpu()).float().mean().item() for pred in preds]\n",
    "    return max(accs)\n",
    "\n",
    "print(emb.shape)\n",
    "print(y_true_list)\n",
    "KNN(torch.tensor(emb), torch.tensor(np.array(y_true_list)), 128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('3.8.12')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44883d22f80f18ef889a1dba7be5a0fad8fd72b0a76884ea66d1ab4eda69ec6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
